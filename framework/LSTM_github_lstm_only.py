# -*- coding: utf-8 -*-
"""vix_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KQS3lb5-A4KgxhSLZH6sixaHLviiSPma
"""

# from google.colab import files
# uploaded=files.upload()

# !pip install statsmodels --upgrade

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Activation
from keras.callbacks import EarlyStopping
import math
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import time

# import statsmodels.formula.api as smf
# from statsmodels.graphics import tsaplots
# import statsmodels.tsa.api as smt
# import statsmodels.api as sm
# import scipy.stats as scs
# from statsmodels.tsa.stattools import adfuller
# from pandas.plotting import autocorrelation_plot
# from statsmodels.graphics.tsaplots import plot_acf
# from statsmodels.tsa.arima_model import ARIMA

seed_value= 42
# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value
import os
os.environ['PYTHONHASHSEED']=str(seed_value)

# 2. Set the `python` built-in pseudo-random generator at a fixed value
import random
random.seed(seed_value)

# 3. Set the `numpy` pseudo-random generator at a fixed value
import numpy as np
np.random.seed(seed_value)

# 4. Set the `tensorflow` pseudo-random generator at a fixed value
import tensorflow as tf
tf.random.set_seed(seed_value)

df=pd.read_csv("vix_data.csv")
df=df.iloc[::-1]
df=df[df['Close']!=0]
df=df.reset_index()
df.drop(['index'], axis=1, inplace=True)
df.head()

log_ret=[]
log_ret.append(0)
for i in range(1, len(df.iloc[:, 0].values)):
  log_ret.append(np.log(df.iloc[i, 4]/df.iloc[i-1, 4]))

ret=[]
ret.append(0)
for i in range(1, len(df.iloc[:, 0].values)):
  ret.append(df.iloc[i, 4]-df.iloc[i-1, 4])

df['log_returns']=log_ret
df['returns']=ret

df['Date_new']=pd.to_datetime(df["Date"])
df["month_year"]=df["Date_new"].dt.strftime('%Y-%m')

# df.describe()

# legend_properties = {'weight':'bold'}
# fig, axes = plt.subplots(figsize=(18,9), dpi=500)
# sns.lineplot(x='Date_new', y='log_returns', data=df, Color='blue')
# #plt.plot(df['log_returns'])
# plt.title("Plot of India VIX Data", fontsize=18, fontweight="bold")
# plt.xlabel("Date", fontsize=18, fontweight="bold")
# plt.ylabel("India VIX log returns", fontsize=18, fontweight="bold")
# plt.xticks(fontsize=16, fontweight="bold")
# plt.legend(fontsize=16, prop=legend_properties)
# plt.yticks(fontsize=16, fontweight="bold")
# #plt.savefig("india_vix_log_ret.jpg")

# df['log_returns'].describe()

# ... (注释掉了中间的大部分代码) ...

"""# **Training the LSTM model**"""

seed_value= 42
# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value
import os
os.environ['PYTHONHASHSEED']=str(seed_value)

# 2. Set the `python` built-in pseudo-random generator at a fixed value
import random
random.seed(seed_value)

# 3. Set the `numpy` pseudo-random generator at a fixed value
import numpy as np
np.random.seed(seed_value)

# 4. Set the `tensorflow` pseudo-random generator at a fixed value
import tensorflow as tf
tf.random.set_seed(seed_value)

first_diff = [df['log_returns'][i] - df['log_returns'][i-1] for i in range(1, len(df['log_returns']))]

rnn_df=pd.DataFrame()
rnn_df['lag_4']=first_diff[:2472]
rnn_df['lag_3']=first_diff[1:2473]
rnn_df['lag_2']=first_diff[2:2474]
rnn_df['lag_1']=first_diff[3:2475]
rnn_df['y']=first_diff[4:2476]

rnn_df.head()

from math import log

def calculate_aic(n, mse, num_params):
	aic = n * log(mse) + 2 * num_params
	return aic

def calculate_bic(n, mse, num_params):
	bic = n * log(mse) + num_params * log(n)
	return bic

X=rnn_df.iloc[:, :4].values
y=rnn_df['y'].values

##splitting dataset into train and test split
train_size=int(len(X)*0.75)
train_X,valid_X=X[0:train_size,:],X[train_size:,:]

Trn_X =train_X.reshape(train_X.shape[0],train_X.shape[1] , 1)
val_X =valid_X.reshape(valid_X.shape[0],valid_X.shape[1] , 1)

Trn_X.shape

val_X.shape

Trn_y=y[:1854]
val_y=y[1854:]

model=Sequential()
model.add(LSTM(80, return_sequences=True, input_shape=(4,1)))
model.add(LSTM(80, return_sequences=True))
model.add(LSTM(40))
model.add(Activation('relu'))
model.add(Dense(1))
model.compile(loss='mean_squared_error',optimizer='adam')
# simple early stopping
es = EarlyStopping(monitor='val_loss', patience=1, mode='auto', verbose=1, restore_best_weights=True)

begin = time.time()
history = model.fit(Trn_X,Trn_y,validation_data=(val_X,val_y), epochs=1000, verbose=1, callbacks=[es])
time.sleep(1)
# store end time
end = time.time()

X_trans=X.reshape(X.shape[0],X.shape[1] , 1)
X_pred=model.predict(X_trans)

"""**AIC on training data**"""

#AIC train
calculate_aic(1854, mean_squared_error(y[:1854],X_pred[:1854]), 4)

"""**AIC on validation data**"""

#AIC val
calculate_aic(618, mean_squared_error(y[1854:],X_pred[1854:]), 4)

"""**BIC on training data**"""

#BIC train
calculate_bic(1854, mean_squared_error(y[:1854],X_pred[:1854]), 4)

"""**BIC on validation data**"""

#BIC val
calculate_bic(618, mean_squared_error(y[1854:],X_pred[1854:]), 4)

X.shape

"""# **Forecasting the volatility of NIFTY50 volatility using LSTM model**"""

#Forecasting using LSTM
lag_4=X[2471, 1]; lag_3=X[2471, 2]; lag_2=X[2471, 3]; lag_1=y[2471];
firstdiff_fore_lstm=[];
for i in range(0, 15):
  x_pred=[]; x_pred.append(lag_4); x_pred.append(lag_3); x_pred.append(lag_2); x_pred.append(lag_1);
  X_pred=np.array(x_pred);
  X_pred=X_pred.reshape(1, 4);
  X_final=X_pred.reshape(1, 4, 1);
  pred=model.predict(X_final);
  firstdiff_fore_lstm.append(pred[0][0]);
  lag_4=lag_3;
  lag_3=lag_2;
  lag_2=lag_1;
  lag_1=pred[0][0];

temp=df['log_returns'].iloc[2474]
forecast_log_ret_lstm=[]
for i in range(0, 15):
  forecast_log_ret_lstm.append(temp+firstdiff_fore_lstm[i])
  temp+=firstdiff_fore_lstm[i]

forecast_lstm=[]
temp=df['Close'].iloc[2474]
for i in range(0, 15):
  forecast_lstm.append(np.exp(forecast_log_ret_lstm[i])*temp)
  temp*=np.exp(forecast_log_ret_lstm[i])

forecast_lstm

"""**Mean absolute percentage error on 5 days forecasting data**"""

#5 days error
from sklearn.metrics import mean_absolute_percentage_error
y_true=[21.22, 20.85, 20.25, 20.31, 19.79, 23.00, 20.46, 20.89, 20.40, 22.49, 22.43, 23.03, 22.69, 23.5, 23.08]
mean_absolute_percentage_error(y_true[:5], forecast_lstm[:5])

"""**Mean absolute percentage error on 10 days forecasting data**"""

#10 days error
from sklearn.metrics import mean_absolute_percentage_error
mean_absolute_percentage_error(y_true[:10], forecast_lstm[:10])

"""**Mean absolute percentage error on 15 days forecasting data**"""

#15 days error
from sklearn.metrics import mean_absolute_percentage_error
mean_absolute_percentage_error(y_true[:], forecast_lstm[:])